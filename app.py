import face_recognition
import numpy as np
from flask import Flask, render_template, request, redirect, url_for, Response
import cv2
import os

app = Flask(__name__)
app.config['MYSQL_URI'] = 'mysql://root:password123@localhost/Attendance_System'


folderPath = 'static/Images'


@app.route('/')
def index():
    return render_template('login.html')


# import face_recognition
# import flask
#
# # Load the Haar cascade for eye detection
# eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')
#
# # Initialize a Flask app
# app = flask.Flask(__name__)
#
# @app.route('/')
# def index():
#     # Capture frames from the camera
#     capture = cv2.VideoCapture(0)
#
#     face_encodings = []
#     while len(face_encodings) < 30:
#         # Read a frame from the camera
#         _, frame = capture.read()
#
#         # Convert the frame to grayscale
#         gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
#
#         # Detect eyes in the frame
#         eyes = eye_cascade.detectMultiScale(gray, 1.3, 5)
#
#         # If eyes are not detected, alert the user to open their eyes
#         if len(eyes) == 0:
#             cv2.putText(frame, "Please open your eyes", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
#
#         # Detect facial landmarks in the frame using the face_recognition library
#         landmarks = face_recognition.face_landmarks(frame)
#
#         # If facial landmarks are not detected, alert the user to show a frontal face
#         if landmarks is None:
#             cv2.putText(frame, "Please show a frontal face", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
#
#         # If eyes and facial landmarks are detected, extract face encodings using the face_recognition library
#         else:
#             encodings = face_recognition.face_encodings(frame)
#
#             # Add the encodings to the list of face encodings
#             face_encodings.extend(encodings)
#
#         # Display the frame
#         cv2.imshow('Frame', frame)
#
#         # Break the loop if the user presses 'q'
#         if cv2.waitKey(1) & 0xFF == ord('q'):
#             break
#
#     # Release the camera
#     capture.release()
#     cv2.destroyAllWindows()
#
#     # Save the face encodings to a file
#     np.save('face_encodings.npy', face_encodings)
#
#     # Return a success message
#     return "Successfully recorded face encodings"
#
# if __name__ == '__main__':
#     app.run()



@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        # Get the form data
        username = request.form['username']
        password = request.form['password']

        # Check the credentials
        # TODO: ADD DATABASE
        if username == 'admin' and password == 'adminadmin':
            # Redirect to the attendance page
            return redirect(url_for('dashboard'))
        else:
            # Redirect back to the login page
            return redirect(url_for('login'))
    else:
        # Render the login template
        return render_template('login.html')


@app.route('/dashboard')
def dashboard():
    return render_template('dashboard.html')


@app.route('/start_attendance')
def start_attendance():
    return render_template('start_attendance.html')


@app.route('/video_feed')
def video_feed():
    # Return the video stream response generated by the record_attendance function
    return Response(record_attendance(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')


def record_attendance():
    # Open the webcam
    cap = cv2.VideoCapture(0)

    # Set to 1280x720
    cap.set(3, 1280)
    cap.set(4, 720)

    # Keep capturing frames until the program is interrupted
    while True:
        # Capture a frame from the webcam
        success, frame = cap.read()

        # Resize frame to 25%
        resized_frame = cv2.resize(frame, (0, 0), None, 0.25, 0.25)

        # Convert color space from BGR to RGB
        resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)

        face_location = face_recognition.face_locations(resized_frame)
        encoded_frame = face_recognition.face_encodings(resized_frame, face_location)

        for face_encode, face_location in zip(encoded_frame, face_location):
            # TODO: Pass in ENCODE_LIST_KNOWN after generating encodings from the list of files
            matches = face_recognition.compare_faces(ENCODE_LIST_KNOWN, face_encode)
            distance = face_recognition.face_distance(ENCODE_LIST_KNOWN, face_encode)

            match_index = np.argmin(distance)

            if matches[match_index]:
                pass    # TODO: from youtube video

        # Encode the frame in JPEG format
        ret, jpeg = cv2.imencode('.jpg', frame)

        # Return the frame as a response
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + jpeg.tobytes() + b'\r\n')

    cap.release()


def generate_encodings(image_list):
    encode_list = []
    for image in image_list:
        # Convert color space from BGR to RGB
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # Calculate the 128-dimensional face encodings for the first face detected
        encode = face_recognition.face_encodings(image)[0]
        encode_list.append(encode)

    return encode_list


if __name__ == '__main__':
    app.run(debug=True, threaded=True)
